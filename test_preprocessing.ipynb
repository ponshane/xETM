{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.format_txt_into_mat import format_from_text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting document frequency of words...\n",
      "building the vocabulary...\n",
      "\tinitial vocabulary size: 103079\n",
      "tokenizing documents and splitting into train/test/valid...\n",
      "  vocabulary after removing words not in train: 96430\n",
      "  number of documents (train): 277375 [this should be equal to 277375]\n",
      "  number of documents (test): 32632 [this should be equal to 32632]\n",
      "  number of documents (valid): 16317 [this should be equal to 16317]\n",
      "removing empty documents...\n",
      "splitting test documents in 2 halves...\n",
      "creating lists of words_indices/doc_indices for docs_tr\n",
      "  len(words_indices_tr): 42530571\n",
      "  len(np.unique(doc_indices_tr)): 277159 [this should be 277159]\n",
      "creating bow representation for docs_tr\n",
      "creating lists of words_indices/doc_indices for docs_ts\n",
      "  len(words_indices_ts): 4979286\n",
      "  len(np.unique(doc_indices_ts)): 32538 [this should be 32538]\n",
      "creating bow representation for docs_ts\n",
      "creating lists of words_indices/doc_indices for docs_ts_h1\n",
      "  len(words_indices_ts_h1): 2481494\n",
      "  len(np.unique(doc_indices_ts_h1)): 32538 [this should be 32538]\n",
      "creating bow representation for docs_ts_h1\n",
      "creating lists of words_indices/doc_indices for docs_ts_h2\n",
      "  len(words_indices_ts_h2): 2497792\n",
      "  len(np.unique(doc_indices_ts_h2)): 32538 [this should be 32538]\n",
      "creating bow representation for docs_ts_h2\n",
      "creating lists of words_indices/doc_indices for docs_va\n",
      "  len(words_indices_va): 2503671\n",
      "  len(np.unique(doc_indices_va)): 16307 [this should be 16307]\n",
      "creating bow representation for docs_va\n",
      "splitting bow into token/value pairs and saving to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evan19983314/.conda/envs/cltm/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "path_text = \"./data/training_all.txt\"\n",
    "path_save = \"./airiti_out/\"\n",
    "format_from_text(path_text, path_save, norm=False, max_df=0.7, min_df=10, ratio={\"training\":0.85, \"testing\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting document frequency of words...\n",
      "building the vocabulary...\n",
      "\tinitial vocabulary size: 44432\n",
      "tokenizing documents and splitting into train/test/valid...\n",
      "  vocabulary after removing words not in train: 42502\n",
      "  number of documents (train): 61312 [this should be equal to 61312]\n",
      "  number of documents (test): 7213 [this should be equal to 7213]\n",
      "  number of documents (valid): 3607 [this should be equal to 3607]\n",
      "removing empty documents...\n",
      "splitting test documents in 2 halves...\n",
      "creating lists of words_indices/doc_indices for docs_tr\n",
      "  len(words_indices_tr): 10151979\n",
      "  len(np.unique(doc_indices_tr)): 61276 [this should be 61276]\n",
      "creating bow representation for docs_tr\n",
      "creating lists of words_indices/doc_indices for docs_ts\n",
      "  len(words_indices_ts): 1189838\n",
      "  len(np.unique(doc_indices_ts)): 7205 [this should be 7205]\n",
      "creating bow representation for docs_ts\n",
      "creating lists of words_indices/doc_indices for docs_ts_h1\n",
      "  len(words_indices_ts_h1): 593052\n",
      "  len(np.unique(doc_indices_ts_h1)): 7205 [this should be 7205]\n",
      "creating bow representation for docs_ts_h1\n",
      "creating lists of words_indices/doc_indices for docs_ts_h2\n",
      "  len(words_indices_ts_h2): 596786\n",
      "  len(np.unique(doc_indices_ts_h2)): 7205 [this should be 7205]\n",
      "creating bow representation for docs_ts_h2\n",
      "creating lists of words_indices/doc_indices for docs_va\n",
      "  len(words_indices_va): 600930\n",
      "  len(np.unique(doc_indices_va)): 3607 [this should be 3607]\n",
      "creating bow representation for docs_va\n",
      "splitting bow into token/value pairs and saving to disk...\n"
     ]
    }
   ],
   "source": [
    "path_text = \"./data/training_all_6011.txt\"\n",
    "path_save = \"./airiti_out_6011/\"\n",
    "np.random.seed(666)\n",
    "format_from_text(path_text, path_save, norm=False, max_df=0.7, min_df=10, ratio={\"training\":0.85, \"testing\": 0.1}, suffix='6011')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('cltm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ab3ba51e6d3161da1c697cc7f8f9d7b45cb15fb9e8a82accd014f21311550bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
